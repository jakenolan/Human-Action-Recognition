{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW78o8M5wuet"
      },
      "source": [
        "---\n",
        "\n",
        "# **Computer Vision (CV) for Human Action Recognition (HAR)**\n",
        "\n",
        "---\n",
        "\n",
        "<br />\n",
        "\n",
        "Work in progress! This is my current work for my computer vision (cv) for human action recognition (HAR) project. My goal is to use use transfer learning with multiple state of the art computer vision models, tested on ImageNet, and apply them to my specific HAR application. This is to test whether the speed of training from transfer learning outweights the possible biases that can be found within the predefined weights of these models. To keep the testing simple, the trainable layers being added on are only dense and dropout layers. For these trainable layers, I am also using Keras Tuner to explore the full potential that these fully adapted models can obtain. Enjoy the code!\n",
        "\n",
        "<br />\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and System Setup"
      ],
      "metadata": {
        "id": "6hXxn-W0rs9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u96Rzi2YZi6u"
      },
      "outputs": [],
      "source": [
        "# Set working environment variable (keep one true)\n",
        "my_machine = False\n",
        "colab = True\n",
        "# Set TPU bool (can be used in colab)\n",
        "# Current versioning error using a TPU so keep false (to be fixed)\n",
        "tpu = False\n",
        "\n",
        "# Assumed packages installed on local machine\n",
        "# If colab install keras tuner (not included in colab)\n",
        "if colab:\n",
        "    %pip install -q -U keras-tuner\n",
        "\n",
        "# Full imports\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib as mp\n",
        "import keras_tuner\n",
        "\n",
        "# Partial imports\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.backend import batch_normalization\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Confirm completion\n",
        "print( \"Everything successfully imported!\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpWLAd0PZi6y"
      },
      "outputs": [],
      "source": [
        "# If on your machine check for GPU and and enable memory growth\n",
        "# Do not need to run if not using a GPU\n",
        "if not tpu:\n",
        "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if not physical_devices:\n",
        "        print( \"No GPU recognized!\" )\n",
        "    else:\n",
        "        print( \"Number of GPUs recognized: \", len(physical_devices) )\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# If using Colab you can connect and init a TPU for training\n",
        "if tpu and colab:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    tpu_stat = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "FVHFHpSSrxdU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SljXq3f5Zi6z"
      },
      "outputs": [],
      "source": [
        "# Collect train and test data from csv files\n",
        "# HAR data found on Kaggle\n",
        "if my_machine:\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    train_set_csv = pd.read_csv( os.path.join(ROOT_DIR, \"Training_set.csv\") )\n",
        "    test_set_csv = pd.read_csv( os.path.join(ROOT_DIR, \"Testing_set.csv\") )\n",
        "\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    upload = files.upload()\n",
        "    train_set_csv = pd.read_csv('Training_set.csv')\n",
        "    test_set_csv = pd.read_csv('Testing_set.csv')\n",
        "\n",
        "num_classes = len(train_set_csv['label'].unique())\n",
        "print( \"Total number of action classes: \", num_classes )\n",
        "print( \"List of action classes: \" )\n",
        "print( train_set_csv['label'].unique() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYUiJHIiZi6z"
      },
      "outputs": [],
      "source": [
        "# Get path to or upload train and test data\n",
        "if my_machine:\n",
        "    TRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\n",
        "    TEST_DIR = os.path.join(ROOT_DIR, \"test\")\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    upload = files.upload()\n",
        "    with zipfile.ZipFile(\"train.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    TRAIN_DIR = \"train\"\n",
        "    with zipfile.ZipFile(\"test.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    TEST_DIR = \"test\"\n",
        "\n",
        "# Create train and validation datasets and apply transformations\n",
        "train_val_image_generator = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "train_dataset = train_val_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_set_csv,\n",
        "    directory=TRAIN_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        ")\n",
        "val_dataset = train_val_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_set_csv,\n",
        "    directory=TRAIN_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "# Create test dataset and apply transformations\n",
        "test_image_generator = ImageDataGenerator()\n",
        "test_dataset = test_image_generator.flow_from_dataframe(\n",
        "    dataframe=test_set_csv, \n",
        "    directory=TEST_DIR,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    shuffle=False,\n",
        "    target_size=(224, 224),\n",
        "    class_mode=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG Model Build and Tuning"
      ],
      "metadata": {
        "id": "yQxfSdqOsH6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zFieFeBZi61"
      },
      "outputs": [],
      "source": [
        "def build_vgg_model(hp):\n",
        "    # Create base cnn layers from VGG16 but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    vgg = Sequential()\n",
        "    pretrained_model= tf.keras.applications.VGG16(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to VGG16 for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    vgg.add( pretrained_model )\n",
        "    vgg.add( Dropout(0.5) )\n",
        "    vgg.add( Flatten() )\n",
        "    vgg.add( Dense(512, activation='relu') )\n",
        "    # Tunable layers\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_1\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    vgg.add( Dense(units=hp.Int(\"units_2\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_2\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    vgg.add( Dense(units=hp.Int(\"units_3\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_3\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    # Output layer\n",
        "    vgg.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    vgg.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Ze7baOaMQC"
      },
      "outputs": [],
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_vgg_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"vgg_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tuner search and get the optimal hyperparamters\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=5)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    vgg = build_vgg_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        vgg = build_vgg_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "vgg.summary()"
      ],
      "metadata": {
        "id": "Ct4xthorAl8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG Training"
      ],
      "metadata": {
        "id": "vTStLGsvsOTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLF55OQ5Zi62"
      },
      "outputs": [],
      "source": [
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_effnet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = vgg.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "vgg.save(\"vgg_har_model.h5\")\n",
        "vgg.save_weights(\"vgg_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"vgg_har_model.h5\")\n",
        "    files.download(\"vgg_har_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet Model Build and Tuning"
      ],
      "metadata": {
        "id": "e4ImaHMjQJwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_effnet_model(hp):\n",
        "    # Create base cnn layers from EfficientNet V2M but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    effnet = Sequential()\n",
        "    pretrained_model= tf.keras.applications.EfficientNetV2M(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to EfficientNet V2M for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    effnet.add( pretrained_model )\n",
        "    effnet.add( Flatten() )\n",
        "    effnet.add( Dense(512, activation='relu') )\n",
        "    effnet.add( Dropout(0.5) )\n",
        "    effnet.add( Dense(units=hp.Int(\"units_0\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_0\")\n",
        "    if dropout:\n",
        "        effnet.add( Dropout(0.5) )\n",
        "    effnet.add( Dense(units=hp.Int(\"units_1\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_1\")\n",
        "    if dropout:\n",
        "        effnet.add( Dropout(0.5) )\n",
        "    # Output layer\n",
        "    effnet.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    effnet.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return effnet"
      ],
      "metadata": {
        "id": "nKf1zQnlSLil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_effnet_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=16,\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"effnet_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "qWUcSecWQJGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tuner search and get the optimal hyperparamters\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=10)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    effnet = build_effnet_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        effnet = build_effnet_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "effnet.summary()"
      ],
      "metadata": {
        "id": "uhHDoRkvRHKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet Training"
      ],
      "metadata": {
        "id": "ri8Xdr1EQUbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_effnet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = effnet.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "effnet.save(\"effnet_har_model.h5\")\n",
        "effnet.save_weights(\"effnet_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"effnet_har_model.h5\")\n",
        "    files.download(\"effnet_har_weights.h5\")"
      ],
      "metadata": {
        "id": "1kj6SYpHQYV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Model Build and Tuning"
      ],
      "metadata": {
        "id": "jh5amI1YEPEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "def build_densenet_model(hp):\n",
        "    # Create base cnn layers from DenseNet but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    densenet = Sequential()\n",
        "    pretrained_model= tf.keras.applications.DenseNet201(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to DenseNet for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    densenet.add( pretrained_model )\n",
        "    densenet.add( Flatten() )\n",
        "    densenet.add( Dense(512, activation='relu') )\n",
        "    densenet.add( Dropout(0.5) )\n",
        "    \"\"\"\n",
        "    densenet.add( Dense(units=hp.Int(\"units_0\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_0\")\n",
        "    if dropout:\n",
        "        densenet.add( Dropout(0.5) )\n",
        "    densenet.add( Dense(units=hp.Int(\"units_1\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_1\")\n",
        "    if dropout:\n",
        "        densenet.add( Dropout(0.5) )\n",
        "    \"\"\"\n",
        "    densenet.add( Dense(256, activation='relu') )\n",
        "    # Output layer\n",
        "    densenet.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    densenet.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return densenet"
      ],
      "metadata": {
        "id": "0jAQniwCEZVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_densenet_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=16,\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"densenet_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "NdE3pv5VEc9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "# Run tuner search and get the optimal hyperparamters\n",
        "\"\"\"\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=10)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\"\"\"\n",
        "tuned_hp = True\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    densenet = build_densenet_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        densenet = build_densenet_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "densenet.summary()"
      ],
      "metadata": {
        "id": "o1AfBlBAc0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Training"
      ],
      "metadata": {
        "id": "-ABI5vC4FAGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_densenet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = densenet.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "densenet.save(\"densenet_har_model.h5\")\n",
        "densenet.save_weights(\"densenet_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"densenet_har_model.h5\")\n",
        "    files.download(\"densenet_har_weights.h5\")"
      ],
      "metadata": {
        "id": "gYDWqSQkFByW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and Results"
      ],
      "metadata": {
        "id": "uUGgmUrsPz5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt0tBLY7Zi63"
      },
      "outputs": [],
      "source": [
        "# Create labels dict for reference\n",
        "labels_ref = (train_dataset.class_indices)\n",
        "labels = {}\n",
        "for name, index in labels_ref.items():\n",
        "    labels[index] = name\n",
        "\n",
        "# Print labels dictionary evenly for a visual\n",
        "print( \"------------------------------\" )\n",
        "print( \"Labels: \" )\n",
        "for index in range(len(labels)):\n",
        "    if index < 10:\n",
        "        print( \" \" + str(index) + \": \" + labels[index] )\n",
        "    else:\n",
        "        print( str(index) + \": \" + labels[index] )\n",
        "\n",
        "# Collect 5 random pictures from test files and run predictions\n",
        "test_files = os.listdir(TEST_DIR)\n",
        "random_numbers = np.random.randint(low=0, high=len(test_files), size=5)\n",
        "for i in random_numbers:\n",
        "    # Collect test file and handle image\n",
        "    test_file = TEST_DIR + \"/\" + test_files[i]\n",
        "    test_image = keras.preprocessing.image.load_img(test_file, target_size=(224, 224))\n",
        "    test_image = keras.preprocessing.image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    test_file = mp.image.imread(test_file)\n",
        "    plot = mp.pyplot.imshow(test_file)\n",
        "    print( \"------------------------------\" )\n",
        "    print( \"\\n\" )\n",
        "    print( test_files[i] )\n",
        "    print( \"\\n\" )\n",
        "    mp.pyplot.show()\n",
        "    print( \"\\n\" )\n",
        "    # Run predictions from tested model\n",
        "    #prediction = cnn.predict([[test_image]])\n",
        "    #prediction = vgg.predict([[test_image]])\n",
        "    prediction = effnet.predict([[test_image]])\n",
        "    results = {}\n",
        "    for index in range(len(prediction[0])):\n",
        "        results[index] = (prediction[0][index])\n",
        "    sorted_results = sorted(results, key=results.get, reverse=True)\n",
        "    for index in sorted_results:\n",
        "        print( labels[index] + \": \" + str(results[index]) )\n",
        "        print( \"\\n\" )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('cvenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b85e13c92cb50cc8954c2f15a1ff4a46104e3ef963a141e57ec86a5992533f71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}