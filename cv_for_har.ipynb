{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW78o8M5wuet"
      },
      "source": [
        "---\n",
        "\n",
        "# **Computer Vision (CV) for Human Action Recognition (HAR)**\n",
        "\n",
        "---\n",
        "\n",
        "<br />\n",
        "\n",
        "Type here...\n",
        "\n",
        "<br />\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and System Setup"
      ],
      "metadata": {
        "id": "6hXxn-W0rs9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u96Rzi2YZi6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9d7347-e5da-4657-ff62-3a7ba401e313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 5.1 MB/s \n",
            "\u001b[?25hEverything successfully imported!\n"
          ]
        }
      ],
      "source": [
        "# Set working environment variable (keep one true)\n",
        "my_machine = False\n",
        "colab = True\n",
        "# Set TPU bool (can be used in colab)\n",
        "# Current versioning error using a TPU so keep false (to be fixed)\n",
        "tpu = False\n",
        "\n",
        "# Assumed packages installed on local machine\n",
        "# If colab install keras tuner (not included in colab)\n",
        "if colab:\n",
        "    %pip install -q -U keras-tuner\n",
        "\n",
        "# Full imports\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib as mp\n",
        "import keras_tuner\n",
        "\n",
        "# Partial imports\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Confirm completion\n",
        "print( \"Everything successfully imported!\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpWLAd0PZi6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14861bbf-9147-4563-c388-78f7a0b2413f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs recognized:  1\n"
          ]
        }
      ],
      "source": [
        "# If on your machine check for GPU and and enable memory growth\n",
        "# Do not need to run if not using a GPU\n",
        "if not tpu:\n",
        "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if not physical_devices:\n",
        "        print( \"No GPU recognized!\" )\n",
        "    else:\n",
        "        print( \"Number of GPUs recognized: \", len(physical_devices) )\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# If using Colab you can connect and init a TPU for training\n",
        "if tpu and colab:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    tpu_stat = tf.distribute.experimental.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "FVHFHpSSrxdU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SljXq3f5Zi6z",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a9bb7f94-5aba-465f-f9fb-62550512695c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21f062d1-df38-4702-ac9a-211294860efb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21f062d1-df38-4702-ac9a-211294860efb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Testing_set.csv to Testing_set.csv\n",
            "Saving Training_set.csv to Training_set.csv\n",
            "Total number of action classes:  15\n",
            "List of action classes: \n",
            "['sitting' 'using_laptop' 'hugging' 'sleeping' 'drinking' 'clapping'\n",
            " 'dancing' 'cycling' 'calling' 'laughing' 'eating' 'fighting'\n",
            " 'listening_to_music' 'running' 'texting']\n"
          ]
        }
      ],
      "source": [
        "# Collect train and test data from csv files\n",
        "# HAR data found on Kaggle\n",
        "if my_machine:\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    train_set_csv = pd.read_csv( os.path.join(ROOT_DIR, \"Training_set.csv\") )\n",
        "    test_set_csv = pd.read_csv( os.path.join(ROOT_DIR, \"Testing_set.csv\") )\n",
        "\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    upload = files.upload()\n",
        "    train_set_csv = pd.read_csv('Training_set.csv')\n",
        "    test_set_csv = pd.read_csv('Testing_set.csv')\n",
        "\n",
        "num_classes = len(train_set_csv['label'].unique())\n",
        "print( \"Total number of action classes: \", num_classes )\n",
        "print( \"List of action classes: \" )\n",
        "print( train_set_csv['label'].unique() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYUiJHIiZi6z",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8e4931be-ce59-406b-ea30-827b6eecedea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69991dc7-a2ea-48f3-9029-8dde7a10a26c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69991dc7-a2ea-48f3-9029-8dde7a10a26c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10080 validated image filenames belonging to 15 classes.\n",
            "Found 2520 validated image filenames belonging to 15 classes.\n",
            "Found 5400 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "from keras.backend import batch_normalization\n",
        "# Get path to or upload train and test data\n",
        "if my_machine:\n",
        "    TRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\n",
        "    TEST_DIR = os.path.join(ROOT_DIR, \"test\")\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    upload = files.upload()\n",
        "    with zipfile.ZipFile(\"train.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    TRAIN_DIR = \"train\"\n",
        "    with zipfile.ZipFile(\"test.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    TEST_DIR = \"test\"\n",
        "\n",
        "# Create train and validation datasets and apply transformations\n",
        "train_val_image_generator = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        ")\n",
        "train_dataset = train_val_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_set_csv,\n",
        "    directory=TRAIN_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        ")\n",
        "val_dataset = train_val_image_generator.flow_from_dataframe(\n",
        "    dataframe=train_set_csv,\n",
        "    directory=TRAIN_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    subset='validation',\n",
        "    shuffle=True,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "# Create test dataset and apply transformations\n",
        "test_image_generator = ImageDataGenerator()\n",
        "test_dataset = test_image_generator.flow_from_dataframe(\n",
        "    dataframe=test_set_csv, \n",
        "    directory=TEST_DIR,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    shuffle=False,\n",
        "    target_size=(224, 224),\n",
        "    class_mode=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG Model Build and Tuning"
      ],
      "metadata": {
        "id": "yQxfSdqOsH6W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zFieFeBZi61"
      },
      "outputs": [],
      "source": [
        "def build_vgg_model(hp):\n",
        "    # Create base cnn layers from VGG16 but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    vgg = Sequential()\n",
        "    pretrained_model= tf.keras.applications.VGG16(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to VGG16 for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    vgg.add( pretrained_model )\n",
        "    vgg.add( Dropout(0.5) )\n",
        "    vgg.add( Flatten() )\n",
        "    vgg.add( Dense(512, activation='relu') )\n",
        "    # Tunable layers\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_1\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    vgg.add( Dense(units=hp.Int(\"units_2\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_2\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    vgg.add( Dense(units=hp.Int(\"units_3\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    vgg.add( Dropout(hp.Float(\"dropout_3\", min_value=0.0, max_value=0.3, step=0.1)) )\n",
        "    # Output layer\n",
        "    vgg.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    vgg.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return vgg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Ze7baOaMQC"
      },
      "outputs": [],
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_vgg_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"vgg_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tuner search and get the optimal hyperparamters\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=5)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    vgg = build_vgg_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        vgg = build_vgg_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "vgg.summary()"
      ],
      "metadata": {
        "id": "Ct4xthorAl8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cf5c75-9bc8-4b16-f46b-286f51e792a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,044,943\n",
            "Trainable params: 330,255\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG Training"
      ],
      "metadata": {
        "id": "vTStLGsvsOTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLF55OQ5Zi62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c69f798-c44e-4126-b511-a5f35846fb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "315/315 [==============================] - 142s 448ms/step - loss: 2.4516 - accuracy: 0.2619 - val_loss: 1.8564 - val_accuracy: 0.3956 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.8730 - accuracy: 0.3868 - val_loss: 1.6412 - val_accuracy: 0.4675 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "315/315 [==============================] - 140s 444ms/step - loss: 1.7282 - accuracy: 0.4425 - val_loss: 1.5830 - val_accuracy: 0.4952 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "315/315 [==============================] - 139s 440ms/step - loss: 1.6653 - accuracy: 0.4563 - val_loss: 1.5171 - val_accuracy: 0.5155 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.6128 - accuracy: 0.4726 - val_loss: 1.4872 - val_accuracy: 0.5218 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "315/315 [==============================] - 139s 440ms/step - loss: 1.5811 - accuracy: 0.4829 - val_loss: 1.4370 - val_accuracy: 0.5440 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "315/315 [==============================] - 140s 443ms/step - loss: 1.5523 - accuracy: 0.4901 - val_loss: 1.4861 - val_accuracy: 0.5119 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "315/315 [==============================] - 139s 442ms/step - loss: 1.5235 - accuracy: 0.5033 - val_loss: 1.4566 - val_accuracy: 0.5373 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "315/315 [==============================] - 139s 443ms/step - loss: 1.4933 - accuracy: 0.5120 - val_loss: 1.4235 - val_accuracy: 0.5468 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.4908 - accuracy: 0.5144 - val_loss: 1.4167 - val_accuracy: 0.5401 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.4623 - accuracy: 0.5208 - val_loss: 1.4360 - val_accuracy: 0.5361 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.4735 - accuracy: 0.5225 - val_loss: 1.4219 - val_accuracy: 0.5544 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.4420 - accuracy: 0.5247 - val_loss: 1.3764 - val_accuracy: 0.5647 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "315/315 [==============================] - 137s 437ms/step - loss: 1.4489 - accuracy: 0.5277 - val_loss: 1.4162 - val_accuracy: 0.5361 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "315/315 [==============================] - 137s 436ms/step - loss: 1.4054 - accuracy: 0.5447 - val_loss: 1.3655 - val_accuracy: 0.5599 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.4023 - accuracy: 0.5423 - val_loss: 1.3937 - val_accuracy: 0.5452 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "315/315 [==============================] - 137s 436ms/step - loss: 1.3794 - accuracy: 0.5479 - val_loss: 1.3763 - val_accuracy: 0.5615 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "315/315 [==============================] - 137s 434ms/step - loss: 1.3878 - accuracy: 0.5442 - val_loss: 1.3725 - val_accuracy: 0.5556 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "315/315 [==============================] - 137s 436ms/step - loss: 1.3094 - accuracy: 0.5651 - val_loss: 1.3330 - val_accuracy: 0.5746 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.2879 - accuracy: 0.5768 - val_loss: 1.3167 - val_accuracy: 0.5746 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.2962 - accuracy: 0.5757 - val_loss: 1.3008 - val_accuracy: 0.5810 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.2839 - accuracy: 0.5814 - val_loss: 1.3099 - val_accuracy: 0.5742 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.2807 - accuracy: 0.5802 - val_loss: 1.2966 - val_accuracy: 0.5837 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.2559 - accuracy: 0.5825 - val_loss: 1.2871 - val_accuracy: 0.5802 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "315/315 [==============================] - 138s 438ms/step - loss: 1.2486 - accuracy: 0.5933 - val_loss: 1.3029 - val_accuracy: 0.5813 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "315/315 [==============================] - 140s 445ms/step - loss: 1.2500 - accuracy: 0.5854 - val_loss: 1.2932 - val_accuracy: 0.5817 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "315/315 [==============================] - 138s 438ms/step - loss: 1.2396 - accuracy: 0.5903 - val_loss: 1.2854 - val_accuracy: 0.5853 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "315/315 [==============================] - 140s 444ms/step - loss: 1.2448 - accuracy: 0.5908 - val_loss: 1.2857 - val_accuracy: 0.5877 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "315/315 [==============================] - 144s 457ms/step - loss: 1.2375 - accuracy: 0.5955 - val_loss: 1.2847 - val_accuracy: 0.5742 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "315/315 [==============================] - 141s 446ms/step - loss: 1.2370 - accuracy: 0.5898 - val_loss: 1.2871 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "315/315 [==============================] - 139s 442ms/step - loss: 1.2124 - accuracy: 0.5997 - val_loss: 1.2850 - val_accuracy: 0.5849 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "315/315 [==============================] - 139s 442ms/step - loss: 1.2335 - accuracy: 0.5903 - val_loss: 1.2788 - val_accuracy: 0.5905 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.2180 - accuracy: 0.5971 - val_loss: 1.2821 - val_accuracy: 0.5817 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "315/315 [==============================] - 140s 443ms/step - loss: 1.2092 - accuracy: 0.6040 - val_loss: 1.2819 - val_accuracy: 0.5829 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "315/315 [==============================] - 139s 441ms/step - loss: 1.2241 - accuracy: 0.5951 - val_loss: 1.2966 - val_accuracy: 0.5746 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "315/315 [==============================] - 138s 438ms/step - loss: 1.1990 - accuracy: 0.6082 - val_loss: 1.3029 - val_accuracy: 0.5810 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "315/315 [==============================] - 139s 440ms/step - loss: 1.1939 - accuracy: 0.6044 - val_loss: 1.2883 - val_accuracy: 0.5810 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "315/315 [==============================] - 140s 445ms/step - loss: 1.1936 - accuracy: 0.6087 - val_loss: 1.2786 - val_accuracy: 0.5825 - lr: 1.0000e-05\n",
            "Epoch 39/100\n",
            "315/315 [==============================] - 139s 440ms/step - loss: 1.1964 - accuracy: 0.6021 - val_loss: 1.2833 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
            "Epoch 40/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.1802 - accuracy: 0.6074 - val_loss: 1.2741 - val_accuracy: 0.5813 - lr: 1.0000e-05\n",
            "Epoch 41/100\n",
            "315/315 [==============================] - 139s 442ms/step - loss: 1.1911 - accuracy: 0.6040 - val_loss: 1.2671 - val_accuracy: 0.5873 - lr: 1.0000e-05\n",
            "Epoch 42/100\n",
            "315/315 [==============================] - 138s 439ms/step - loss: 1.1882 - accuracy: 0.6100 - val_loss: 1.2748 - val_accuracy: 0.5893 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_95a14f56-1c59-4ce1-b050-2cd4492e2e36\", \"vgg_har_model.h5\", 62899832)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1ba7622-b2f1-44fb-b0ce-be63fe729275\", \"vgg_har_weights.h5\", 60220408)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_effnet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = vgg.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "vgg.save(\"vgg_har_model.h5\")\n",
        "vgg.save_weights(\"vgg_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"vgg_har_model.h5\")\n",
        "    files.download(\"vgg_har_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet Model Build and Tuning"
      ],
      "metadata": {
        "id": "e4ImaHMjQJwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_effnet_model(hp):\n",
        "    # Create base cnn layers from VGG16 but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    effnet = Sequential()\n",
        "    pretrained_model= tf.keras.applications.EfficientNetV2M(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to VGG16 for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    effnet.add( pretrained_model )\n",
        "    effnet.add( Flatten() )\n",
        "    effnet.add( Dense(512, activation='relu') )\n",
        "    effnet.add( Dropout(0.5) )\n",
        "    effnet.add( Dense(units=hp.Int(\"units_0\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_0\")\n",
        "    if dropout:\n",
        "        effnet.add( Dropout(0.5) )\n",
        "    effnet.add( Dense(units=hp.Int(\"units_1\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_1\")\n",
        "    if dropout:\n",
        "        effnet.add( Dropout(0.5) )\n",
        "    # Output layer\n",
        "    effnet.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    effnet.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return effnet"
      ],
      "metadata": {
        "id": "nKf1zQnlSLil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_effnet_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=16,\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"effnet_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWUcSecWQJGE",
        "outputId": "142c3fb3-7536-4d31-f2a3-a82a12eab1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 256, 'step': 128, 'sampling': None}\n",
            "dropout_0 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 128, 'step': 64, 'sampling': None}\n",
            "dropout_1 (Boolean)\n",
            "{'default': False, 'conditions': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tuner search and get the optimal hyperparamters\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=10)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    effnet = build_effnet_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        effnet = build_effnet_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "effnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhHDoRkvRHKj",
        "outputId": "ee1289e4-7c6b-42a6-e7b8-dfb0c03dc822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetv2-s (Functiona  (None, 1280)             20331360  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               655872    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,054,831\n",
            "Trainable params: 723,471\n",
            "Non-trainable params: 20,331,360\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet Training"
      ],
      "metadata": {
        "id": "ri8Xdr1EQUbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_effnet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = effnet.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "effnet.save(\"effnet_har_model.h5\")\n",
        "effnet.save_weights(\"effnet_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"effnet_har_model.h5\")\n",
        "    files.download(\"effnet_har_weights.h5\")"
      ],
      "metadata": {
        "id": "1kj6SYpHQYV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Model Build and Tuning"
      ],
      "metadata": {
        "id": "jh5amI1YEPEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_densenet_model(hp):\n",
        "    # Create base cnn layers from VGG16 but cut off dense layers to use our own instead\n",
        "    # Use imagenet weights and lock them to be untrainable\n",
        "    densenet = Sequential()\n",
        "    pretrained_model= tf.keras.applications.DenseNet201(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "    for layer in pretrained_model.layers:\n",
        "            layer.trainable=False\n",
        "    # Add dense layers to VGG16 for our personal use with 15 classes output\n",
        "    # Use keras tuner for number of internal dense layers and number of nodes for each dense layer\n",
        "    densenet.add( pretrained_model )\n",
        "    densenet.add( Flatten() )\n",
        "    densenet.add( Dense(512, activation='relu') )\n",
        "    densenet.add( Dropout(0.5) )\n",
        "    \"\"\"\n",
        "    densenet.add( Dense(units=hp.Int(\"units_0\", min_value=128, max_value=256, step=128), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_0\")\n",
        "    if dropout:\n",
        "        densenet.add( Dropout(0.5) )\n",
        "    densenet.add( Dense(units=hp.Int(\"units_1\", min_value=64, max_value=128, step=64), activation='relu') )\n",
        "    dropout = hp.Boolean(\"dropout_1\")\n",
        "    if dropout:\n",
        "        densenet.add( Dropout(0.5) )\n",
        "    \"\"\"\n",
        "    densenet.add( Dense(256, activation='relu') )\n",
        "    # Output layer\n",
        "    densenet.add( Dense(15, activation='softmax') )\n",
        "    # Compile model and return\n",
        "    densenet.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return densenet"
      ],
      "metadata": {
        "id": "0jAQniwCEZVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tuner search and check summary\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_densenet_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=16,\n",
        "    overwrite=True,\n",
        "    directory=\"/\",\n",
        "    project_name=\"densenet_for_har\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "NdE3pv5VEc9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tuner search and get the optimal hyperparamters\n",
        "\"\"\"\n",
        "tuner.search(x=train_dataset, validation_data=val_dataset, epochs=10)\n",
        "tuned_hp = tuner.get_best_hyperparameters()[0]\n",
        "\"\"\"\n",
        "tuned_hp = True\n",
        "\n",
        "# Check for tpu and then build optimally tuned model\n",
        "if not tpu:\n",
        "    densenet = build_densenet_model(tuned_hp)\n",
        "if tpu and colab:\n",
        "    with tpu_stat.scope():\n",
        "        densenet = build_densenet_model(tuned_hp)\n",
        "\n",
        "# Show summary of optimal model\n",
        "densenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1AfBlBAc0eS",
        "outputId": "efd0a4d7-318a-4e21-aa56-19889fd878e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet201 (Functional)    (None, 1920)              18321984  \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 1920)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               983552    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 15)                3855      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,440,719\n",
            "Trainable params: 1,118,735\n",
            "Non-trainable params: 18,321,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet Training"
      ],
      "metadata": {
        "id": "-ABI5vC4FAGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------ WORK IN PROGRESS ------------------------------\n",
        "# Set callback function for early stopping to save best epoch\n",
        "callbacks = [\n",
        "    ModelCheckpoint(filepath='best_densenet_har_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.1, min_lr=1.0e-7),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=10),\n",
        "]\n",
        "\n",
        "# Fit tuned model and save resulting weights\n",
        "history = densenet.fit_generator(generator=train_dataset, validation_data=val_dataset, epochs=100, callbacks=callbacks)\n",
        "densenet.save(\"densenet_har_model.h5\")\n",
        "densenet.save_weights(\"densenet_har_weights.h5\")\n",
        "\n",
        "# If using Colab it will save weights to local machine\n",
        "if colab:\n",
        "    from google.colab import files\n",
        "    files.download(\"densenet_har_model.h5\")\n",
        "    files.download(\"densenet_har_weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gYDWqSQkFByW",
        "outputId": "17f5383d-3d84-4cbb-ee00-94c9a7d18bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 52s 137ms/step - loss: 2.7737 - accuracy: 0.1469 - val_loss: 2.3770 - val_accuracy: 0.2246 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "315/315 [==============================] - 38s 121ms/step - loss: 2.4747 - accuracy: 0.1830 - val_loss: 2.3850 - val_accuracy: 0.2111 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.4275 - accuracy: 0.1855 - val_loss: 2.3158 - val_accuracy: 0.2306 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "315/315 [==============================] - 38s 121ms/step - loss: 2.3851 - accuracy: 0.2068 - val_loss: 2.3308 - val_accuracy: 0.2524 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.3453 - accuracy: 0.2206 - val_loss: 2.3036 - val_accuracy: 0.2516 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.3140 - accuracy: 0.2275 - val_loss: 2.2302 - val_accuracy: 0.2766 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "315/315 [==============================] - 38s 121ms/step - loss: 2.2877 - accuracy: 0.2415 - val_loss: 2.2318 - val_accuracy: 0.2873 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.2568 - accuracy: 0.2488 - val_loss: 2.2075 - val_accuracy: 0.2774 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.2425 - accuracy: 0.2575 - val_loss: 2.1807 - val_accuracy: 0.3083 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "315/315 [==============================] - 38s 121ms/step - loss: 2.2189 - accuracy: 0.2647 - val_loss: 2.2007 - val_accuracy: 0.2837 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.1841 - accuracy: 0.2780 - val_loss: 2.1469 - val_accuracy: 0.3250 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.1710 - accuracy: 0.2789 - val_loss: 2.1304 - val_accuracy: 0.3234 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "315/315 [==============================] - 39s 123ms/step - loss: 2.1625 - accuracy: 0.2814 - val_loss: 2.1383 - val_accuracy: 0.3163 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "315/315 [==============================] - 38s 122ms/step - loss: 2.1429 - accuracy: 0.2833 - val_loss: 2.1369 - val_accuracy: 0.3187 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "315/315 [==============================] - 38s 122ms/step - loss: 2.1446 - accuracy: 0.2900 - val_loss: 2.1616 - val_accuracy: 0.3131 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "315/315 [==============================] - 38s 122ms/step - loss: 2.1366 - accuracy: 0.2871 - val_loss: 2.1665 - val_accuracy: 0.3230 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "315/315 [==============================] - 39s 124ms/step - loss: 2.0545 - accuracy: 0.3180 - val_loss: 2.0821 - val_accuracy: 0.3468 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 2.0095 - accuracy: 0.3296 - val_loss: 2.0639 - val_accuracy: 0.3540 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "315/315 [==============================] - 39s 124ms/step - loss: 2.0013 - accuracy: 0.3294 - val_loss: 2.0607 - val_accuracy: 0.3468 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9876 - accuracy: 0.3327 - val_loss: 2.0591 - val_accuracy: 0.3433 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9802 - accuracy: 0.3379 - val_loss: 2.0575 - val_accuracy: 0.3440 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9710 - accuracy: 0.3423 - val_loss: 2.0564 - val_accuracy: 0.3448 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9696 - accuracy: 0.3411 - val_loss: 2.0559 - val_accuracy: 0.3464 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9636 - accuracy: 0.3409 - val_loss: 2.0528 - val_accuracy: 0.3433 - lr: 1.0000e-05\n",
            "Epoch 25/100\n",
            "315/315 [==============================] - 40s 126ms/step - loss: 1.9491 - accuracy: 0.3469 - val_loss: 2.0480 - val_accuracy: 0.3468 - lr: 1.0000e-05\n",
            "Epoch 26/100\n",
            "315/315 [==============================] - 40s 126ms/step - loss: 1.9469 - accuracy: 0.3480 - val_loss: 2.0455 - val_accuracy: 0.3484 - lr: 1.0000e-05\n",
            "Epoch 27/100\n",
            "315/315 [==============================] - 39s 125ms/step - loss: 1.9572 - accuracy: 0.3433 - val_loss: 2.0446 - val_accuracy: 0.3500 - lr: 1.0000e-05\n",
            "Epoch 28/100\n",
            "315/315 [==============================] - 38s 121ms/step - loss: 1.9475 - accuracy: 0.3474 - val_loss: 2.0451 - val_accuracy: 0.3512 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6ac64a22-251a-46ae-90f0-56e31551c8fd\", \"densenet_har_model.h5\", 87901256)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4504ef9b-6ecd-4d8c-96a8-20ceae7edf40\", \"densenet_har_weights.h5\", 78599256)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and Results"
      ],
      "metadata": {
        "id": "uUGgmUrsPz5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt0tBLY7Zi63"
      },
      "outputs": [],
      "source": [
        "# Create labels dict for reference\n",
        "labels_ref = (train_dataset.class_indices)\n",
        "labels = {}\n",
        "for name, index in labels_ref.items():\n",
        "    labels[index] = name\n",
        "\n",
        "# Print labels dictionary evenly for a visual\n",
        "print( \"------------------------------\" )\n",
        "print( \"Labels: \" )\n",
        "for index in range(len(labels)):\n",
        "    if index < 10:\n",
        "        print( \" \" + str(index) + \": \" + labels[index] )\n",
        "    else:\n",
        "        print( str(index) + \": \" + labels[index] )\n",
        "\n",
        "# Collect 5 random pictures from test files and run predictions\n",
        "test_files = os.listdir(TEST_DIR)\n",
        "random_numbers = np.random.randint(low=0, high=len(test_files), size=5)\n",
        "for i in random_numbers:\n",
        "    # Collect test file and handle image\n",
        "    test_file = TEST_DIR + \"/\" + test_files[i]\n",
        "    test_image = keras.preprocessing.image.load_img(test_file, target_size=(224, 224))\n",
        "    test_image = keras.preprocessing.image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    test_file = mp.image.imread(test_file)\n",
        "    plot = mp.pyplot.imshow(test_file)\n",
        "    print( \"------------------------------\" )\n",
        "    print( \"\\n\" )\n",
        "    print( test_files[i] )\n",
        "    print( \"\\n\" )\n",
        "    mp.pyplot.show()\n",
        "    print( \"\\n\" )\n",
        "    # Run predictions from tested model\n",
        "    #prediction = cnn.predict([[test_image]])\n",
        "    #prediction = vgg.predict([[test_image]])\n",
        "    prediction = effnet.predict([[test_image]])\n",
        "    results = {}\n",
        "    for index in range(len(prediction[0])):\n",
        "        results[index] = (prediction[0][index])\n",
        "    sorted_results = sorted(results, key=results.get, reverse=True)\n",
        "    for index in sorted_results:\n",
        "        print( labels[index] + \": \" + str(results[index]) )\n",
        "        print( \"\\n\" )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6hXxn-W0rs9P",
        "FVHFHpSSrxdU",
        "yQxfSdqOsH6W",
        "vTStLGsvsOTK",
        "e4ImaHMjQJwe",
        "ri8Xdr1EQUbr",
        "jh5amI1YEPEt",
        "-ABI5vC4FAGK",
        "uUGgmUrsPz5b"
      ],
      "name": "cv_for_har.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('cvenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "b85e13c92cb50cc8954c2f15a1ff4a46104e3ef963a141e57ec86a5992533f71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}